{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8108908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import statistics as stats\n",
    "import argparse\n",
    "from torch.utils.data import Sampler\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules import Module\n",
    "# Set device\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Dataset loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   \n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee164c-3aca-4626-b7a2-7a34fb65f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def class_cluster_loss(prototypes, features, labels, c_values, margin=1.0 ):\n",
    "    \"\"\"\n",
    "    Compute the Class Cluster Loss for a batch.\n",
    "    \n",
    "    :param prototypes: Tensor of shape (num_classes, feature_dim) containing class prototypes\n",
    "    :param features: Tensor of shape (batch_size, feature_dim) containing features of batch samples\n",
    "    :param labels: LongTensor of shape (batch_size,) containing labels of batch samples\n",
    "    :param margin: Float, the margin parameter for the loss calculation\n",
    "    :param c: Float, the central distance parameter for intra-class compactness\n",
    "    :return: Class Cluster Loss value for the batch\n",
    "    \"\"\"\n",
    "    n_classes = prototypes.shape[0]\n",
    "    loss = 0.0\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        # Selecting the current class prototype and corresponding features and labels\n",
    "        current_prototype = prototypes[i]\n",
    "        class_mask = labels == i\n",
    "        class_features = features[class_mask]\n",
    "        #print(\"Prototype shape:\", current_prototype.shape)\n",
    "        #print(\"Class features shape:\", class_features.shape)\n",
    "\n",
    "        \n",
    "        # Calculating distances from the current class features to its prototype\n",
    "        pos_distances = torch.norm(class_features - current_prototype, p=2, dim=1)\n",
    "        # Calculate c as the mean of these distances\n",
    "        # Calculate c as the mean of these distances\n",
    "        c = pos_distances.mean()\n",
    "        #print('c', c)\n",
    "        # Distance to the farthest positive example\n",
    "        D_pro_max_p = torch.max(pos_distances)\n",
    "        \n",
    "        # Calculating distances to the prototype from features of other classes (negative examples)\n",
    "        neg_mask = ~class_mask\n",
    "        neg_features = features[neg_mask]\n",
    "        neg_distances = torch.norm(neg_features - current_prototype, p=2, dim=1)\n",
    "        \n",
    "        # Distance to the closest negative example\n",
    "        if len(neg_distances) > 0:\n",
    "            D_pro_min_n = torch.min(neg_distances)\n",
    "        else:\n",
    "            # Handling cases where a class might have all the samples in the batch\n",
    "            D_pro_min_n = torch.tensor(0.0).to(features.device)\n",
    "        \n",
    "        # Computing the first term of the CCL\n",
    "        loss += F.relu(D_pro_max_p - D_pro_min_n + margin)\n",
    "        # Ensure you're using the correct 'c' for the current class\n",
    "        current_c = c\n",
    "        # Additional term to ensure the farthest positive is not too far\n",
    "        loss += F.relu(D_pro_max_p - current_c)\n",
    "    \n",
    "    # Averaging the loss over the number of classes\n",
    "    loss /= n_classes\n",
    "    \n",
    "    return loss\n",
    "import torch\n",
    "\n",
    "def calculate_central_distance(prototypes, features, labels):\n",
    "    num_classes = prototypes.shape[0]\n",
    "    c_values = torch.zeros(num_classes, device=prototypes.device)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        class_mask = labels == i\n",
    "        #print(class_mask)\n",
    "        class_features = features[class_mask]\n",
    "        \n",
    "        if class_features.nelement() == 0:  # Check if there are no features for the current class\n",
    "            c_values[i] = torch.tensor(0.0, device=prototypes.device)  # Assign nan or another placeholder\n",
    "            continue  # Skip the rest of the loop for this class\n",
    "        \n",
    "        distances = torch.norm(class_features - prototypes[i], dim=1, p=2)\n",
    "        c_values[i] = distances.mean()  # This will not be nan since class_features is not empty\n",
    "\n",
    "    return c_values\n",
    "\n",
    "margin = 0.00005\n",
    "n_classes = 4\n",
    "\n",
    "class PrototypicalLoss(Module):\n",
    "    '''\n",
    "    Loss class deriving from Module for the prototypical loss function defined below\n",
    "    '''\n",
    "    def __init__(self, n_support):\n",
    "        super(PrototypicalLoss, self).__init__()\n",
    "        self.n_support = n_support\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return prototypical_loss(input, target)#, self.n_support)\n",
    "\n",
    "def prototypical_loss(input, target):#, n_support):\n",
    "    '''\n",
    "    Inspired by https://github.com/jakesnell/prototypical-networks/blob/master/protonets/models/few_shot.py\n",
    "\n",
    "    Compute the barycentres by averaging the features of n_support\n",
    "    samples for each class in target, computes then the distances from each\n",
    "    samples' features to each one of the barycentres, computes the\n",
    "    log_probability for each n_query samples for each one of the current\n",
    "    classes, of appartaining to a class c, loss and accuracy are then computed\n",
    "    and returned\n",
    "    Args:\n",
    "    - input: the model output for a batch of samples\n",
    "    - target: ground truth for the above batch of samples\n",
    "    - n_support: number of samples to keep in account when computing\n",
    "      barycentres, for each one of the current classes\n",
    "    '''\n",
    "    target_cpu = target.to(device)\n",
    "    input_cpu = input.to(device)\n",
    "    features=input_cpu\n",
    "    support_features, support_labels = features[:n_support], labels[:n_support]\n",
    "    query_features, query_labels = features[n_support:], labels[n_support:]\n",
    "        \n",
    "    def supp_idxs(c):\n",
    "        # FIXME when torch will support where as np\n",
    "        return target_cpu.eq(c).nonzero()[:n_support].squeeze(1)\n",
    "\n",
    "    # FIXME when torch.unique will be available on cuda too\n",
    "    classes = torch.unique(target_cpu)\n",
    "    n_classes = len(classes)\n",
    "    #print('n_classes:',n_classes)\n",
    "    # FIXME when torch will support where as np\n",
    "    # assuming n_query, n_target constants\n",
    "    n_query = target_cpu.eq(classes[0].item()).sum().item() - n_support\n",
    "    #print('n_query:',n_query)\n",
    "    support_idxs = list(map(supp_idxs, classes))\n",
    "\n",
    "    prototypes = torch.stack([input_cpu[idx_list].mean(0) for idx_list in support_idxs])\n",
    "    # FIXME when torch will support where as np\n",
    "    query_idxs = torch.stack(list(map(lambda c: target_cpu.eq(c).nonzero()[n_support:], classes))).view(-1)\n",
    "\n",
    "    query_samples = input.to(device)[query_idxs]\n",
    "    dists = euclidean_dist(query_samples, prototypes)\n",
    "\n",
    "    log_p_y = F.log_softmax(-dists, dim=1).view(n_classes, n_query, -1)\n",
    "\n",
    "    target_inds = torch.arange(0, n_classes, device=device)\n",
    "    target_inds = target_inds.view(n_classes, 1, 1)\n",
    "    target_inds = target_inds.expand(n_classes, n_query, 1).long()\n",
    "   # print('target_inds:',target_inds)\n",
    "\n",
    "    loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "    _, y_hat = log_p_y.max(2)\n",
    "    #print('y_hat',y_hat)\n",
    "    acc_val = y_hat.eq(target_inds.squeeze(2)).float().mean()\n",
    "    target_inds = target_inds.squeeze(2)\n",
    "    \n",
    "    c_values = calculate_central_distance(prototypes, support_features, support_labels)\n",
    "    #print(c_values)\n",
    "    # Initialize class cluster loss\n",
    "    cc_loss = 0.0\n",
    "    \n",
    "    # Compute Class Cluster Loss\n",
    "    # Note: Assuming the prototypes calculation and euclidean_dist are defined as before\n",
    "    # Loop over each class to calculate class cluster loss\n",
    "    for i in range(4):#n_classes):\n",
    "        # Assuming calculate_class_cluster_loss function calculates the loss for a single class\n",
    "        cc_loss += class_cluster_loss(prototypes[i], query_features, query_labels, c_values[i],margin)\n",
    "    \n",
    "    # Normalize the class cluster loss by the number of classes\n",
    "    #cc_loss /= n_classes\n",
    "    #print('cc_loss',cc_loss,'\\nloss_val',loss_val)\n",
    "    \n",
    "\n",
    "         # Combine the losses\n",
    "    # Here, you might want to add a weighting factor to either loss depending on their importance\n",
    "    total_loss = loss_val + cc_loss  # Adjust this combination based on your needs\n",
    " \n",
    "    return total_loss,  acc_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f14ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "\n",
    "class PrototypicalBatchSampler(Sampler):\n",
    "    def __init__(self, labels, classes_per_batch, support_per_class, queries_per_class):\n",
    "        self.labels = labels\n",
    "        self.classes_per_batch = classes_per_batch\n",
    "        self.support_per_class = support_per_class\n",
    "        self.queries_per_class = queries_per_class\n",
    "\n",
    "        self.classes, self.counts = np.unique(self.labels, return_counts=True)\n",
    "        self.indices = {c: np.where(self.labels == c)[0] for c in self.classes}\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(len(self)):\n",
    "            batch = []\n",
    "            selected_classes = np.random.choice(self.classes, self.classes_per_batch, replace=False)\n",
    "            \n",
    "            for c in selected_classes:\n",
    "                indices = np.random.choice(self.indices[c], self.support_per_class + self.queries_per_class, replace=False)\n",
    "                batch.extend(indices)\n",
    "\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels) // (self.classes_per_batch * (self.support_per_class + self.queries_per_class))\n",
    "\n",
    "\n",
    "    #Test with other network design\n",
    "\n",
    "\n",
    "class PrototypicalNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(PrototypicalNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input tensor if it's not already a flat vector\n",
    "        x = x.view(x.size(0), -1)  # Reshape input to [batch_size, input_size]\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class PrototypicalNetwork2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(PrototypicalNetwork, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "    # coding=utf-8\n",
    "\n",
    "\n",
    "\n",
    "class PrototypicalLoss(Module):\n",
    "    '''\n",
    "    Loss class deriving from Module for the prototypical loss function defined below\n",
    "    '''\n",
    "    def __init__(self, n_support):\n",
    "        super(PrototypicalLoss, self).__init__()\n",
    "        self.n_support = n_support\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return prototypical_loss(input, target)#, self.n_support)\n",
    "\n",
    "\n",
    "def euclidean_dist(x, y):\n",
    "    '''\n",
    "    Compute euclidean distance between two tensors\n",
    "    '''\n",
    "    # x: N x D\n",
    "    # y: M x D\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    if d != y.size(1):\n",
    "        raise Exception\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)\n",
    "\n",
    "\n",
    "\n",
    "def prototypical_loss(input, target):#, n_support):\n",
    "    '''\n",
    "    Inspired by https://github.com/jakesnell/prototypical-networks/blob/master/protonets/models/few_shot.py\n",
    "\n",
    "    Compute the barycentres by averaging the features of n_support\n",
    "    samples for each class in target, computes then the distances from each\n",
    "    samples' features to each one of the barycentres, computes the\n",
    "    log_probability for each n_query samples for each one of the current\n",
    "    classes, of appartaining to a class c, loss and accuracy are then computed\n",
    "    and returned\n",
    "    Args:\n",
    "    - input: the model output for a batch of samples\n",
    "    - target: ground truth for the above batch of samples\n",
    "    - n_support: number of samples to keep in account when computing\n",
    "      barycentres, for each one of the current classes\n",
    "    '''\n",
    "    target_cpu = target.to(device)\n",
    "    input_cpu = input.to(device)\n",
    "\n",
    "    def supp_idxs(c):\n",
    "        # FIXME when torch will support where as np\n",
    "        return target_cpu.eq(c).nonzero()[:n_support].squeeze(1)\n",
    "\n",
    "    # FIXME when torch.unique will be available on cuda too\n",
    "    classes = torch.unique(target_cpu)\n",
    "    n_classes = len(classes)\n",
    "    #print('n_classes:',n_classes)\n",
    "    # FIXME when torch will support where as np\n",
    "    # assuming n_query, n_target constants\n",
    "    n_query = target_cpu.eq(classes[0].item()).sum().item() - n_support\n",
    "    #print('n_query:',n_query)\n",
    "    support_idxs = list(map(supp_idxs, classes))\n",
    "\n",
    "    prototypes = torch.stack([input_cpu[idx_list].mean(0) for idx_list in support_idxs])\n",
    "    # FIXME when torch will support where as np\n",
    "    query_idxs = torch.stack(list(map(lambda c: target_cpu.eq(c).nonzero()[n_support:], classes))).view(-1)\n",
    "\n",
    "    query_samples = input.to(device)[query_idxs]\n",
    "    dists = euclidean_dist(query_samples, prototypes)\n",
    "\n",
    "    log_p_y = F.log_softmax(-dists, dim=1).view(n_classes, n_query, -1)\n",
    "\n",
    "    target_inds = torch.arange(0, n_classes, device=device)\n",
    "    target_inds = target_inds.view(n_classes, 1, 1)\n",
    "    target_inds = target_inds.expand(n_classes, n_query, 1).long()\n",
    "   # print('target_inds:',target_inds)\n",
    "\n",
    "    loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "    _, y_hat = log_p_y.max(2)\n",
    "    #print('y_hat',y_hat)\n",
    "    acc_val = y_hat.eq(target_inds.squeeze(2)).float().mean()\n",
    "    target_inds = target_inds.squeeze(2)\n",
    "    \n",
    "    \n",
    "    return loss_val,  acc_val\n",
    "\n",
    "def compute_prototypes(support_embeddings, support_labels, n_classes):\n",
    "    \"\"\"Compute class prototypes from support set embeddings.\"\"\"\n",
    "    prototypes = []\n",
    "    for i in range(n_classes):\n",
    "        # Extract embeddings belonging to class i\n",
    "        class_embeddings = support_embeddings[support_labels == i]\n",
    "        # Compute the mean of these embeddings\n",
    "        prototype = class_embeddings.mean(0)\n",
    "        prototypes.append(prototype)\n",
    "    return torch.stack(prototypes)\n",
    "\n",
    "def classify_embeddings(query_embeddings, prototypes):\n",
    "    \"\"\"Classify query embeddings based on the nearest class prototype.\"\"\"\n",
    "    # Calculate the distances from each query embedding to each prototype\n",
    "    distances = euclidean_dist(query_embeddings, prototypes)\n",
    "\n",
    "    # Find the index of the nearest prototype for each query embedding\n",
    "    nearest_prototype_indices = distances.argmin(1)\n",
    "\n",
    "    soft_assignments = F.softmax(-distances, dim=1) \n",
    "    \n",
    "    return nearest_prototype_indices,soft_assignments\n",
    "\n",
    "def get_support_set_embeddings(support_loader, proto_net):\n",
    "    \"\"\"Obtain embeddings and labels from the support set.\"\"\"\n",
    "    support_embeddings = []\n",
    "    support_labels = []\n",
    "\n",
    "    proto_net.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, labels in support_loader:  # support_loader loads the support set\n",
    "            \n",
    "            features = features.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            #dim_features, _ = dim_model(features)\n",
    "        \n",
    "            embeddings = proto_net(features)\n",
    "            support_embeddings.append(embeddings.cpu().numpy())\n",
    "            support_labels.append(labels.cpu().numpy())\n",
    "        return np.concatenate(support_embeddings, axis=0), np.concatenate(support_labels, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae81f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = ImageFolder(root='Alzheimer_s Dataset/train', transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "# assuming `your_dataset` is an instance of a class that extends torch.utils.data.Dataset\n",
    "\n",
    "# Create your DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Calculate the number of instances in each class\n",
    "class_counts = {}\n",
    "for _, label in dataloader:\n",
    "    label = label.item()\n",
    "    if label in class_counts:\n",
    "        class_counts[label] += 1\n",
    "    else:\n",
    "        class_counts[label] = 1\n",
    "\n",
    "# Sort the counts for better visualization\n",
    "sorted_counts = dict(sorted(class_counts.items()))\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(sorted_counts.keys(), sorted_counts.values())\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of instances')\n",
    "plt.title('Distribution of instances per class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04819a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_features = []\n",
    "true_labels = []  # Assuming you have some labels\n",
    "num_classes = 4\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:  # DataLoader for your labeled subset\n",
    "        images = images.to(device)\n",
    "        \n",
    "        encoded_features.extend(images.cpu().numpy())\n",
    "        true_labels.extend(labels.numpy())\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_features, true_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' and 'labels' are your datasets\n",
    "train_dataset = FewShotDataset(X_train, y_train)\n",
    "test_dataset = FewShotDataset(X_test, y_test)\n",
    "\n",
    "train_sampler = PrototypicalBatchSampler(y_train, classes_per_batch=4, support_per_class=10, queries_per_class=5)\n",
    "test_sampler = PrototypicalBatchSampler(y_test, classes_per_batch=4, support_per_class=10, queries_per_class=5)\n",
    " \n",
    "train_loader = DataLoader(train_dataset, batch_sampler=train_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f32a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the input_size to match the size of your extracted features\n",
    "input_size =  224 * 224 * 3 #input_size = 64  # Replace with the actual size of your features\n",
    "hidden_size = 128 #26  # 256 This can be adjusted as per your model's requirement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff16c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_net = ResnetPrototypicalNetwork(input_size, hidden_size).to(device)\n",
    "# Prototypical Loss\n",
    "n_support = 10  # Adjust as needed\n",
    "proto_loss_fn = PrototypicalLoss(n_support).to(device)\n",
    "optimizer = torch.optim.Adam(proto_net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa093adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "avg_losses_for_plot = []  # To store average losses for plotting\n",
    "avg_accuracies_for_plot = []  # To store average accuracies for plotting\n",
    "\n",
    "# Training loop  hidden_size = 26 \n",
    "for epoch in range(100):\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = proto_net(features)\n",
    "        loss, acc = proto_loss_fn(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += acc.item()\n",
    "        total_batches += 1\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = total_loss / total_batches\n",
    "    avg_accuracy = total_accuracy / total_batches\n",
    "    \n",
    "    # Store metrics\n",
    "    epoch_losses.append(avg_loss)\n",
    "    epoch_accuracies.append(avg_accuracy)\n",
    "    \n",
    "    # Store metrics for plotting\n",
    "    avg_losses_for_plot.append(avg_loss)\n",
    "    avg_accuracies_for_plot.append(avg_accuracy)\n",
    "    \n",
    "    # Log the training progress\n",
    "    print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}, Average Accuracy: {avg_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877690c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming you have a DataLoader named support_loader for the support set\n",
    "support_embeddings, support_labels = get_support_set_embeddings(test_loader, proto_net)\n",
    "# Convert to PyTorch tensors\n",
    "support_embeddings = torch.tensor(support_embeddings).to(device)\n",
    "support_labels = torch.tensor(support_labels).to(device)\n",
    "\n",
    "n_classes = 4\n",
    "# Compute the prototypes\n",
    "prototypes = compute_prototypes(support_embeddings, support_labels, n_classes)\n",
    "# In your evaluation loop\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        query_embeddings = proto_net(features)\n",
    "        predicted_labels = classify_embeddings(query_embeddings, prototypes)\n",
    "proto_net.eval()  # Assuming 'proto_net' is your Prototypical Network model\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:  # Replace eval_loader with your DataLoader for evaluation\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = proto_net(features)\n",
    "        preds, soft_assignments = classify_embeddings(embeddings,prototypes)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d2b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture and trained parameters\n",
    "torch.save(proto_net.state_dict(), \"ResNet_protonet.pth\")\n",
    "# Load the trained parameters\n",
    "#model.load_state_dict(torch.load(\"trained_protonet.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e408f-41c9-4fa6-ab0d-e97f67ffbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = proto_net\n",
    "# Assuming proto_net is your Prototypical Network\n",
    "resnet.eval()  # Set the model to evaluation mode\n",
    " \n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, batch_labels in test_loader:  # data_loader is your DataLoader\n",
    "        features = features.to(device)\n",
    "        #dim_features, _ = dim_model(features) \n",
    "        batch_embeddings = resnet(features)  # Get the embeddings\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "        labels.append(batch_labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "embeddings = np.concatenate(embeddings, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d0e88-811c-4e40-ac04-ab182eebf026",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c8e79-3e15-4874-b23b-e1ce7bc8a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['MD','MOD','ND','VMD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d52cc-d6fb-4a5b-b476-99b507b7a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.1, random_state=10)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    " # Apply t-SNE transformation\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "embeddings_2d = tsne.fit_transform(X_test)\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette(['blue', 'red', 'green', 'orange'])\n",
    "# Define the marker styles if desired\n",
    "markers = ['o']\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 4))\n",
    "# Use seaborn to get a nicer plot\n",
    "# Scatter plot for each class using the color palette\n",
    "for i, color in zip(range(len(class_names)), palette):\n",
    "    indices = y_test == i\n",
    "    sns.scatterplot(x=embeddings_2d[indices , 0], y=embeddings_2d[indices , 1], \n",
    "                    label=f'{class_names[i]}', color=color, s=100, \n",
    "                    alpha=0.7, edgecolor='k', linewidth=0.5, marker=markers[i % len(markers)])\n",
    "\n",
    "# Improving the legend and placing it outside the plot\n",
    "#plt.legend(title='Classes', loc='center left', bbox_to_anchor=(1, 0.5), fontsize='large', title_fontsize='20')\n",
    "\n",
    "# Adding title and labels with larger font sizes\n",
    "plt.title('Embeddings of ProtoNet1 (ResNet18)', fontsize=14)\n",
    "plt.xlabel('t-SNE x', fontsize=9)\n",
    "plt.ylabel('t-SNE y', fontsize=9)\n",
    "\n",
    "# Adding grid with dashed lines\n",
    "plt.grid(True, linestyle='--')\n",
    "\n",
    "# Tight layout often provides a better subplot arrangement\n",
    "plt.tight_layout()\n",
    "plt.savefig('emb_resnet1.png', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af9fca",
   "metadata": {},
   "source": [
    "## MobileNetPrototypicalNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MobileNetPrototypicalNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MobileNetPrototypicalNetwork, self).__init__()\n",
    "        # Load a pre-trained MobileNet model\n",
    "        self.mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        \n",
    "        # Remove the classifier to use as a feature extractor\n",
    "        # For MobileNetV2, features before the classifier are stored in 'features'\n",
    "        self.features = self.mobilenet.features\n",
    "        \n",
    "        # MobileNetV2 outputs features of size 1280 for each image\n",
    "        # Adjust the input size of the linear layer accordingly\n",
    "        self.additional_layers = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling to reduce spatial dimensions\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 4)  # Adjust the number here to match MobileNetV2's output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using the MobileNet backbone\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Pass through additional layers\n",
    "        embedding = self.additional_layers(x)\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aed9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNet_proto_net = MobileNetPrototypicalNetwork(input_size, hidden_size).to(device)\n",
    "# Prototypical Loss\n",
    "n_support = 10  # Adjust as needed\n",
    "proto_loss_fn = PrototypicalLoss(n_support).to(device)\n",
    "optimizer = torch.optim.Adam(MobileNet_proto_net.parameters(), lr=1e-4)\n",
    "epoch_losses = []\n",
    "epoch_accuracies = [] \n",
    "mobilenet_avg_losses_for_plot = []  # To store average losses for plotting\n",
    "mobilenet_avg_accuracies_for_plot = []  # To store average accuracies for plotting\n",
    "\n",
    "# Training loop  hidden_size = 26 \n",
    "for epoch in range(100):\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "        #output = proto_net(features)\n",
    "        #loss, acc, predictions, true_labels = proto_loss_fn(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Extract features from the pre-trained DIM model\n",
    "        #with torch.no_grad():\n",
    "        #/    dim_features, _ = dim_model(features)\n",
    "\n",
    "        # Now, use dim_features as the input to your ProtoNet model\n",
    "        output = MobileNet_proto_net(features)\n",
    "        loss, acc = proto_loss_fn(output, labels)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += acc.item()\n",
    "        total_batches += 1\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = total_loss / total_batches\n",
    "    avg_accuracy = total_accuracy / total_batches\n",
    "    \n",
    "    # Store metrics\n",
    "    epoch_losses.append(avg_loss)\n",
    "    epoch_accuracies.append(avg_accuracy)\n",
    "    \n",
    "    mobilenet_avg_losses_for_plot.append(avg_loss)\n",
    "    mobilenet_avg_accuracies_for_plot.append(avg_accuracy)\n",
    "    \n",
    "    # Log the training progress\n",
    "    print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}, Average Accuracy: {avg_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e07266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataLoader named support_loader for the support set\n",
    "support_embeddings, support_labels = get_support_set_embeddings(test_loader, MobileNet_proto_net)\n",
    "# Convert to PyTorch tensors\n",
    "support_embeddings = torch.tensor(support_embeddings).to(device)\n",
    "support_labels = torch.tensor(support_labels).to(device)\n",
    "\n",
    "n_classes = 4\n",
    "# Compute the prototypes\n",
    "prototypes = compute_prototypes(support_embeddings, support_labels, n_classes)\n",
    "# In your evaluation loop\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        query_embeddings = MobileNet_proto_net(features)\n",
    "        predicted_labels = classify_embeddings(query_embeddings, prototypes)\n",
    "MobileNet_proto_net.eval()  # Assuming 'proto_net' is your Prototypical Network model\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:  # Replace eval_loader with your DataLoader for evaluation\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = MobileNet_proto_net(features)\n",
    "        preds, soft_assignments = classify_embeddings(embeddings,prototypes)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5608e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture and trained parameters\n",
    "torch.save(MobileNet_proto_net.state_dict(), \"MobileNet_protonet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae510a-db27-429d-9e0b-3cb150ee1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNet = MobileNet_proto_net\n",
    "# Assuming you have embeddings_2d and y_test from your t-SNE and actual class data\n",
    "# Here, we're going to use class_names for the legend instead of 'Class {i}'\n",
    "MobileNet.eval()  # Set the model to evaluation mode\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, batch_labels in test_loader:  # data_loader is your DataLoader\n",
    "        features = features.to(device)\n",
    "        #dim_features, _ = dim_model(features) \n",
    "        batch_embeddings = MobileNet(features)  # Get the embeddings\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "        labels.append(batch_labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "embeddings = np.concatenate(embeddings, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Apply t-SNE transformation\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "embeddings_2d = tsne.fit_transform(X_test)\n",
    "\n",
    "palette = sns.color_palette(['blue', 'red', 'green', 'orange'])\n",
    "markers = ['o','o','o','o']  # Different markers for each class\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "# Scatter plot for each class using the color palette and actual class names for the legend\n",
    "for i, color in zip(range(len(class_names)), palette):\n",
    "    indices = y_test == i\n",
    "    sns.scatterplot(\n",
    "        x=embeddings_2d[indices, 0], y=embeddings_2d[indices, 1], \n",
    "        label=class_names[i], color=color, s=100, \n",
    "        alpha=0.7, edgecolor='k', linewidth=0.5, marker=markers[i]\n",
    "    )\n",
    "\n",
    "# Improving the legend and placing it outside the plot\n",
    "plt.legend(title='Classes',   bbox_to_anchor=(1, 0.5), fontsize='small', title_fontsize='9')\n",
    "\n",
    "# Adding title and labels with larger font sizes\n",
    "plt.title('Embeddings of ProtoNet3 (MobileNet)', fontsize=14)\n",
    "plt.xlabel('t-SNE x', fontsize=9)\n",
    "plt.ylabel('t-SNE y', fontsize=9)\n",
    "\n",
    "# Adding grid with dashed lines\n",
    "plt.grid(True, linestyle='--')\n",
    "\n",
    "# Tight layout often provides a better subplot arrangement\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('emb_mobilenet.png', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc81a72",
   "metadata": {},
   "source": [
    "## VGGPrototypicalNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGPrototypicalNetwork(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(VGGPrototypicalNetwork, self).__init__()\n",
    "        # Load a pre-trained VGG model\n",
    "        self.vgg = models.vgg16(pretrained=True)\n",
    "        \n",
    "        # Use VGG as a feature extractor\n",
    "        self.features = self.vgg.features\n",
    "        self.avgpool = self.vgg.avgpool\n",
    "\n",
    "        # Flatten the output and pass it through additional layers for feature embedding\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 7 * 7, hidden_size),  # Embedding layer\n",
    "            nn.ReLU(True)\n",
    "            # Removed the final classification layer to focus on embeddings\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using the VGG backbone\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        # Generate embeddings suitable for prototypical network\n",
    "        embedding = self.embedding(x)\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_net = VGGPrototypicalNetwork(128).to(device)\n",
    "# Prototypical Loss\n",
    "n_support = 10  # Adjust as needed\n",
    "proto_loss_fn = PrototypicalLoss(n_support).to(device)\n",
    "optimizer = torch.optim.Adam(proto_net.parameters(), lr=1e-4)\n",
    "epoch_losses = []\n",
    "epoch_accuracies = [] \n",
    "vgg_avg_losses_for_plot = []\n",
    "vgg_avg_accuracies_for_plot = []\n",
    "\n",
    "\n",
    "# Training loop  hidden_size = 26 \n",
    "for epoch in range(100):\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "        #output = proto_net(features)\n",
    "        #loss, acc, predictions, true_labels = proto_loss_fn(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Extract features from the pre-trained DIM model\n",
    "        #with torch.no_grad():\n",
    "        #/    dim_features, _ = dim_model(features)\n",
    "\n",
    "        # Now, use dim_features as the input to your ProtoNet model\n",
    "        output = proto_net(features)\n",
    "        #print(output.shape)\n",
    "        loss, acc = proto_loss_fn(output, labels)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += acc.item()\n",
    "        total_batches += 1\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = total_loss / total_batches\n",
    "    avg_accuracy = total_accuracy / total_batches\n",
    "    \n",
    "    # Store metrics\n",
    "    epoch_losses.append(avg_loss)\n",
    "    epoch_accuracies.append(avg_accuracy)\n",
    "    vgg_avg_losses_for_plot.append(avg_loss)\n",
    "    vgg_avg_accuracies_for_plot.append(avg_accuracy)\n",
    "    \n",
    "    # Log the training progress\n",
    "    print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}, Average Accuracy: {avg_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41edd3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataLoader named support_loader for the support set\n",
    "support_embeddings, support_labels = get_support_set_embeddings(test_loader,proto_net)\n",
    "# Convert to PyTorch tensors\n",
    "support_embeddings = torch.tensor(support_embeddings).to(device)\n",
    "support_labels = torch.tensor(support_labels).to(device)\n",
    "\n",
    "n_classes = 4\n",
    "# Compute the prototypes\n",
    "prototypes = compute_prototypes(support_embeddings, support_labels, n_classes)\n",
    "# In your evaluation loop\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        query_embeddings = proto_net(features)\n",
    "        predicted_labels = classify_embeddings(query_embeddings, prototypes)\n",
    "proto_net.eval()  # Assuming 'proto_net' is your Prototypical Network model\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:  # Replace eval_loader with your DataLoader for evaluation\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = proto_net(features)\n",
    "        preds, soft_assignments = classify_embeddings(embeddings,prototypes)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bac7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture and trained parameters\n",
    "torch.save(proto_net.state_dict(), \"VGG_protonet.pth\")\n",
    "# Load the trained parameters\n",
    "#model.load_state_dict(torch.load(\"trained_protonet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d46ea-a311-4ab1-a079-644e7dc6f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg = proto_net\n",
    "\n",
    "vgg.eval()  # Set the model to evaluation mode\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, batch_labels in test_loader:  # data_loader is your DataLoader\n",
    "        features = features.to(device)\n",
    "        #dim_features, _ = dim_model(features) \n",
    "        batch_embeddings = vgg(features)  # Get the embeddings\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "        labels.append(batch_labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "embeddings = np.concatenate(embeddings, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.1, random_state=42)\n",
    " \n",
    " # Apply t-SNE transformation\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "embeddings_2d = tsne.fit_transform(X_test)\n",
    "\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette(['blue', 'red', 'green', 'orange'])\n",
    "# Define the marker styles if desired\n",
    "markers = ['o']\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 4))\n",
    "# Use seaborn to get a nicer plot\n",
    "# Scatter plot for each class using the color palette\n",
    "for i, color in zip(range(len(class_names)), palette):\n",
    "    indices = y_test == i\n",
    "    sns.scatterplot(x=embeddings_2d[indices , 0], y=embeddings_2d[indices , 1], \n",
    "                    label=f'{class_names[i]}', color=color, s=100, \n",
    "                    alpha=0.7, edgecolor='k', linewidth=0.5, marker=markers[i % len(markers)])\n",
    "\n",
    "# Adding title and labels with larger font sizes\n",
    "plt.title('Embeddings of ProtoNet5 (VGG16)', fontsize=14)\n",
    "plt.xlabel('t-SNE x', fontsize=9)\n",
    "plt.ylabel('t-SNE y', fontsize=9)\n",
    "\n",
    "\n",
    "# Adding grid with dashed lines\n",
    "plt.grid(True, linestyle='--')\n",
    "\n",
    "# Tight layout often provides a better subplot arrangement\n",
    "plt.tight_layout()\n",
    "plt.savefig('emb_vgg.png', dpi=300)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf6f04",
   "metadata": {},
   "source": [
    "## EfficientNetPrototypicalNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import torchvision.models as models\n",
    "\n",
    "class EfficientNetPrototypicalNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, efficientnet_version='b0', weights_path=None):\n",
    "        super(EfficientNetPrototypicalNetwork, self).__init__()\n",
    "        # Load a pre-trained EfficientNet model\n",
    "        self.efficientnet = EfficientNet.from_pretrained(f'efficientnet-{efficientnet_version}', weights_path=weights_path)\n",
    "        \n",
    "        # Remove the classifier to use as a feature extractor\n",
    "        # For EfficientNet, features before the classifier are stored in 'extract_features'\n",
    "        self.features = self.efficientnet.extract_features\n",
    "        \n",
    "        # EfficientNet outputs features of variable size depending on the architecture\n",
    "        # Adjust the input size of the linear layer accordingly\n",
    "        self.additional_layers = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling to reduce spatial dimensions\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        # The output size of EfficientNet varies depending on its architecture\n",
    "        # You may need to manually specify the input size for the linear layer\n",
    "        self.linear = nn.Linear(self.efficientnet._fc.in_features, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using the EfficientNet backbone\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Pass through additional layers\n",
    "        x = self.additional_layers(x)\n",
    "        \n",
    "        # Linear layer to obtain the final embedding\n",
    "        embedding = self.linear(x)\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019db32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_net = EfficientNetPrototypicalNetwork(input_size,hidden_size).to(device)\n",
    "# Prototypical Loss\n",
    "n_support = 10  # Adjust as needed\n",
    "proto_loss_fn = PrototypicalLoss(n_support).to(device)\n",
    "optimizer = torch.optim.Adam(proto_net.parameters(), lr=1e-4)\n",
    "epoch_losses = []\n",
    "epoch_accuracies = [] \n",
    "eff_avg_losses_for_plot = []\n",
    "eff_avg_accuracies_for_plot = []\n",
    "\n",
    "\n",
    "# Training loop  hidden_size = 26 \n",
    "for epoch in range(100):\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = proto_net(features)\n",
    "        loss, acc = proto_loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += acc.item()\n",
    "        total_batches += 1\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = total_loss / total_batches\n",
    "    avg_accuracy = total_accuracy / total_batches\n",
    "    \n",
    "    # Store metrics\n",
    "    epoch_losses.append(avg_loss)\n",
    "    epoch_accuracies.append(avg_accuracy)\n",
    "    eff_avg_losses_for_plot.append(avg_loss)\n",
    "    eff_avg_accuracies_for_plot.append(avg_accuracy)\n",
    "\n",
    "    \n",
    "    # Log the training progress\n",
    "    print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}, Average Accuracy: {avg_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cdd5d9-8e9c-4add-aa07-b8f8dd607c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataLoader named support_loader for the support set\n",
    "support_embeddings, support_labels = get_support_set_embeddings(test_loader,proto_net)\n",
    "# Convert to PyTorch tensors\n",
    "support_embeddings = torch.tensor(support_embeddings).to(device)\n",
    "support_labels = torch.tensor(support_labels).to(device)\n",
    "\n",
    "n_classes = 4\n",
    "# Compute the prototypes\n",
    "prototypes = compute_prototypes(support_embeddings, support_labels, n_classes)\n",
    "# In your evaluation loop\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        query_embeddings = proto_net(features)\n",
    "        predicted_labels = classify_embeddings(query_embeddings, prototypes)\n",
    "proto_net.eval()  # Assuming 'proto_net' is your Prototypical Network model\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:  # Replace eval_loader with your DataLoader for evaluation\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = proto_net(features)\n",
    "        preds, soft_assignments = classify_embeddings(embeddings,prototypes)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture and trained parameters\n",
    "torch.save(proto_net.state_dict(), \"EfficientNet_protonet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab65e6-ee1e-4ff6-add1-655a0b3caba4",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Assuming proto_net is your Prototypical Network\n",
    "#efficientnet\n",
    "proto_net.eval()  # Set the model to evaluation mode\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, batch_labels in test_loader:  # data_loader is your DataLoader\n",
    "        features = features.to(device)\n",
    "        #dim_features, _ = dim_model(features) \n",
    "        batch_embeddings = proto_net(features)  # Get the embeddings\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "        labels.append(batch_labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "embeddings = np.concatenate(embeddings, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.1, random_state=42)\n",
    " \n",
    " # Apply t-SNE transformation\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "embeddings_2d = tsne.fit_transform(X_test)\n",
    "\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette(['blue', 'red', 'green', 'orange'])\n",
    "# Define the marker styles if desired\n",
    "markers = ['o']\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 4))\n",
    "# Use seaborn to get a nicer plot\n",
    "# Scatter plot for each class using the color palette\n",
    "for i, color in zip(range(len(class_names)), palette):\n",
    "    indices = y_test == i\n",
    "    sns.scatterplot(x=embeddings_2d[indices , 0], y=embeddings_2d[indices , 1], \n",
    "                    label=f'{class_names[i]}', color=color, s=100, \n",
    "                    alpha=0.7, edgecolor='k', linewidth=0.5, marker=markers[i % len(markers)])\n",
    "\n",
    "# Adding title and labels with larger font sizes\n",
    "plt.title('Embeddings of ProtoNet4 (EfficientNet)', fontsize=14)\n",
    "plt.xlabel('t-SNE x', fontsize=9)\n",
    "plt.ylabel('t-SNE y', fontsize=9)\n",
    "\n",
    "\n",
    "\n",
    "# Adding grid with dashed lines\n",
    "plt.grid(True, linestyle='--')\n",
    "\n",
    "# Tight layout often provides a better subplot arrangement\n",
    "plt.tight_layout()\n",
    "plt.savefig('emb_efficientnet.png', dpi=300)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1728076d",
   "metadata": {},
   "source": [
    "## ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class Resnet34PrototypicalNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Resnet34PrototypicalNetwork, self).__init__()\n",
    "        # Load a pre-trained ResNet model\n",
    "        self.resnet = models.resnet34(pretrained=True)\n",
    "        \n",
    "        # Remove the fully connected layer (classifier) to use as a feature extractor\n",
    "        self.features = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        \n",
    "        # Flatten the output to [batch_size, 512] before passing to the linear layer\n",
    "        self.additional_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, hidden_size)  # Adjust the number here to match ResNet's output\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features using the ResNet backbone\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Pass through any additional layers\n",
    "        embedding = self.additional_layers(x)\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the input_size to match the size of your extracted features\n",
    "input_size =  224 * 224 * 3 #input_size = 64  # Replace with the actual size of your features\n",
    "hidden_size = 128 #26  # 256 This can be adjusted as per your model's requirement\n",
    "\n",
    "proto_net = Resnet34PrototypicalNetwork(input_size, hidden_size).to(device)\n",
    "# Prototypical Loss\n",
    "n_support = 10  # Adjust as needed\n",
    "proto_loss_fn = PrototypicalLoss(n_support).to(device)\n",
    "optimizer = torch.optim.Adam(proto_net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ecef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoch_losses = []\n",
    "epoch_accuracies = [] \n",
    "resnet34_avg_losses_for_plot = []\n",
    "resnet34_avg_accuracies_for_plot = []\n",
    "\n",
    "# Training loop  hidden_size = 26 \n",
    "for epoch in range(100):\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "        #output = proto_net(features)\n",
    "        #loss, acc, predictions, true_labels = proto_loss_fn(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Extract features from the pre-trained DIM model\n",
    "        #with torch.no_grad():\n",
    "        #/    dim_features, _ = dim_model(features)\n",
    "\n",
    "        # Now, use dim_features as the input to your ProtoNet model\n",
    "        output = proto_net(features)\n",
    "        loss, acc = proto_loss_fn(output, labels)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += acc.item()\n",
    "        total_batches += 1\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = total_loss / total_batches\n",
    "    avg_accuracy = total_accuracy / total_batches\n",
    "    \n",
    "    # Store metrics\n",
    "    epoch_losses.append(avg_loss)\n",
    "    epoch_accuracies.append(avg_accuracy)\n",
    "    resnet34_avg_losses_for_plot.append(avg_loss)\n",
    "    resnet34_avg_accuracies_for_plot.append(avg_accuracy)\n",
    "    # Log the training progress\n",
    "    print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}, Average Accuracy: {avg_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming you have a DataLoader named support_loader for the support set\n",
    "support_embeddings, support_labels = get_support_set_embeddings(test_loader, proto_net)\n",
    "# Convert to PyTorch tensors\n",
    "support_embeddings = torch.tensor(support_embeddings).to(device)\n",
    "support_labels = torch.tensor(support_labels).to(device)\n",
    "\n",
    "n_classes = 4\n",
    "# Compute the prototypes\n",
    "prototypes = compute_prototypes(support_embeddings, support_labels, n_classes)\n",
    "# In your evaluation loop\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        query_embeddings = proto_net(features)\n",
    "        predicted_labels = classify_embeddings(query_embeddings, prototypes)\n",
    "proto_net.eval()  # Assuming 'proto_net' is your Prototypical Network model\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:  # Replace eval_loader with your DataLoader for evaluation\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = proto_net(features)\n",
    "        preds, soft_assignments = classify_embeddings(embeddings,prototypes)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(all_labels, all_preds, digits=4))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a50fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture and trained parameters\n",
    "torch.save(proto_net.state_dict(), \"ResNet34_protonet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741f5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Assuming proto_net is your Prototypical Network\n",
    "resnet34.eval()  # Set the model to evaluation mode\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, batch_labels in test_loader:  # data_loader is your DataLoader\n",
    "        features = features.to(device)\n",
    "        #dim_features, _ = dim_model(features) \n",
    "        batch_embeddings = resnet34(features)  # Get the embeddings\n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "        labels.append(batch_labels.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "embeddings = np.concatenate(embeddings, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Apply t-SNE transformation\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "embeddings_2d = tsne.fit_transform(X_test)\n",
    "\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette(['blue', 'red', 'green', 'orange'])\n",
    "# Define the marker styles if desired\n",
    "markers = ['o']\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 4))\n",
    "# Use seaborn to get a nicer plot\n",
    "# Scatter plot for each class using the color palette\n",
    "for i, color in zip(range(len(class_names)), palette):\n",
    "    indices = y_test == i\n",
    "    sns.scatterplot(x=embeddings_2d[indices , 0], y=embeddings_2d[indices , 1], \n",
    "                    label=f'{class_names[i]}', color=color, s=100, \n",
    "                    alpha=0.7, edgecolor='k', linewidth=0.5, marker=markers[i % len(markers)])\n",
    "\n",
    "# Adding title and labels with larger font sizes\n",
    "plt.title('Embeddings of ProtoNet2 (ResNet34)', fontsize=14)\n",
    "plt.xlabel('t-SNE x', fontsize=9)\n",
    "plt.ylabel('t-SNE y', fontsize=9)\n",
    "\n",
    "# Adding grid with dashed lines\n",
    "plt.grid(True, linestyle='--')\n",
    "\n",
    "# Tight layout often provides a better subplot arrangement\n",
    "plt.tight_layout()\n",
    "plt.savefig('emb_renet34.png', dpi=300)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4320e954",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b54bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load models\n",
    "\n",
    "resnet = ResnetPrototypicalNetwork(input_size, hidden_size).to(device)\n",
    "\n",
    "resnet.load_state_dict(torch.load(\"ResNet18_protonet_class.pth\"))\n",
    "\n",
    "resnet34 = Resnet34PrototypicalNetwork(input_size, hidden_size).to(device)\n",
    "\n",
    "resnet34.load_state_dict(torch.load(\"ResNet34_protonet_class.pth\"))\n",
    "\n",
    "eff = EfficientNetPrototypicalNetwork(128,4).to(device)\n",
    "\n",
    "eff.load_state_dict(torch.load(\"EfficientNet_protonet_class.pth\"))\n",
    "\n",
    "\n",
    "mobilenet = MobileNetPrototypicalNetwork(input_size, hidden_size).to(device)\n",
    "\n",
    "mobilenet.load_state_dict(torch.load(\"MobileNet_protonet_class.pth\"))  \n",
    "\n",
    "vgg = VGGPrototypicalNetwork(128).to(device)\n",
    "\n",
    "vgg.load_state_dict(torch.load(\"vgg_protonet_class.pth\"))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the models to evaluation mode\n",
    "resnet.eval()\n",
    "resnet34.eval()\n",
    "eff.eval()\n",
    "mobilenet.eval()\n",
    "vgg.eval()\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=1e-4)\n",
    "\n",
    "true_labels = []\n",
    "# Initialize lists to store predictions and probabilities for each model\n",
    "all_resnet_preds = []\n",
    "all_resnet_labels = []\n",
    "all_resnet_probs = []\n",
    "\n",
    "all_resnet34_preds = []\n",
    "all_resnet34_labels = []\n",
    "all_resnet34_probs = []\n",
    "\n",
    "all_eff_preds = []\n",
    "all_eff_labels = []\n",
    "all_eff_probs = []\n",
    "\n",
    "all_m_preds = []\n",
    "all_m_labels = []\n",
    "all_m_probs = []\n",
    "\n",
    "all_vgg_preds = []\n",
    "all_vgg_labels = []\n",
    "all_vgg_probs = []\n",
    "\n",
    "\n",
    "# Assuming you have a DataLoader named support_loader for the support set\n",
    "resnet_support_embeddings, resnet_support_labels = get_support_set_embeddings(test_loader, resnet)\n",
    "# Convert to PyTorch tensors\n",
    "resnet_support_embeddings = torch.tensor(resnet_support_embeddings).to(device)\n",
    "resnet_support_labels = torch.tensor(resnet_support_labels).to(device)\n",
    "# Compute the prototypes\n",
    "resnet_prototypes = compute_prototypes(resnet_support_embeddings, resnet_support_labels, n_classes)\n",
    "\n",
    "\n",
    "# Assuming you have a DataLoader named support_loader for the support set\n",
    "resnet34_support_embeddings, resnet34_support_labels = get_support_set_embeddings(test_loader, resnet34)\n",
    "# Convert to PyTorch tensors\n",
    "resnet34_support_embeddings = torch.tensor(resnet34_support_embeddings).to(device)\n",
    "resnet34_support_labels = torch.tensor(resnet34_support_labels).to(device)\n",
    "# Compute the prototypes\n",
    "resnet34_prototypes = compute_prototypes(resnet34_support_embeddings, resnet34_support_labels, n_classes)\n",
    "\n",
    "\n",
    "# Assuming you have a DataLoader named support_loader for the support set\n",
    "eff_support_embeddings, eff_support_labels = get_support_set_embeddings(test_loader, eff)\n",
    "# Convert to PyTorch tensors\n",
    "eff_support_embeddings = torch.tensor(eff_support_embeddings).to(device)\n",
    "eff_support_labels = torch.tensor(eff_support_labels).to(device)\n",
    "# Compute the prototypes\n",
    "eff_prototypes = compute_prototypes(eff_support_embeddings, eff_support_labels, n_classes)\n",
    "\n",
    "# Assuming you have a DataLoader named support_loader for the support set\n",
    "m_support_embeddings, m_support_labels = get_support_set_embeddings(test_loader, mobilenet)\n",
    "# Convert to PyTorch tensors\n",
    "m_support_embeddings = torch.tensor(m_support_embeddings).to(device)\n",
    "m_support_labels = torch.tensor(m_support_labels).to(device)\n",
    "# Compute the prototypes\n",
    "m_prototypes = compute_prototypes(m_support_embeddings, m_support_labels, n_classes)\n",
    "\n",
    "# Assuming you have a DataLoader named support_loader for the support set\n",
    "vgg_support_embeddings, vgg_support_labels = get_support_set_embeddings(test_loader, vgg)\n",
    "# Convert to PyTorch tensors\n",
    "vgg_support_embeddings = torch.tensor(vgg_support_embeddings).to(device)\n",
    "vgg_support_labels = torch.tensor(vgg_support_labels).to(device)\n",
    "# Compute the prototypes\n",
    "vgg_prototypes = compute_prototypes(vgg_support_embeddings, vgg_support_labels, n_classes)\n",
    "\n",
    "\n",
    "# In your evaluation loop\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        resnet_query_embeddings = resnet(features)\n",
    "        preds, soft_assignments = classify_embeddings(resnet_query_embeddings, resnet_prototypes)\n",
    "        all_resnet_preds.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        all_resnet_labels.extend(labels.cpu().numpy())\n",
    "        all_resnet_probs.extend(soft_assignments.cpu().numpy())  # Collect soft assignment probabilities\n",
    "\n",
    "        \n",
    "        resnet34_query_embeddings = resnet34(features)\n",
    "        preds, soft_assignments = classify_embeddings(resnet34_query_embeddings, resnet34_prototypes)\n",
    "        all_resnet34_preds.extend(preds.cpu().numpy())\n",
    "        all_resnet34_labels.extend(labels.cpu().numpy())\n",
    "        all_resnet34_probs.extend(soft_assignments.cpu().numpy())  # Collect soft assignment probabilities\n",
    "\n",
    "        eff_query_embeddings = eff(features)\n",
    "        preds, soft_assignments = classify_embeddings(eff_query_embeddings, eff_prototypes)\n",
    "        all_eff_preds.extend(preds.cpu().numpy())\n",
    "        all_eff_labels.extend(labels.cpu().numpy())\n",
    "        all_eff_probs.extend(soft_assignments.cpu().numpy())  # Collect soft assignment probabilities\n",
    "                        \n",
    "        m_query_embeddings = mobilenet(features)\n",
    "        preds, soft_assignments = classify_embeddings(m_query_embeddings, m_prototypes)\n",
    "        all_m_preds.extend(preds.cpu().numpy())\n",
    "        all_m_labels.extend(labels.cpu().numpy())\n",
    "        all_m_probs.extend(soft_assignments.cpu().numpy())  # Collect soft assignment probabilities\n",
    "        \n",
    "        vgg_query_embeddings = vgg(features)\n",
    "        preds, soft_assignments = classify_embeddings(vgg_query_embeddings, vgg_prototypes)\n",
    "        all_vgg_preds.extend(preds.cpu().numpy())\n",
    "        all_vgg_labels.extend(labels.cpu().numpy())\n",
    "        all_vgg_probs.extend(soft_assignments.cpu().numpy())  # Collect soft assignment probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9335ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_resnet34_labels, all_resnet34_preds)\n",
    "print(\"----------------ResNet34--------------------\\n\",f'Accuracy: {accuracy}')\n",
    "print(classification_report(all_resnet34_labels, all_resnet34_preds, digits=4))\n",
    "\n",
    "accuracy = accuracy_score(all_resnet_labels, all_resnet_preds)\n",
    "print(\"----------------ResNet18--------------------\\n\",f'Accuracy: {accuracy}')\n",
    "print(classification_report(all_resnet_labels, all_resnet_preds, digits=4))\n",
    "\n",
    "accuracy = accuracy_score(all_eff_labels, all_eff_preds)\n",
    "print(\"----------------EfficientNEt--------------------\\n\",f'Accuracy: {accuracy}')\n",
    "print(classification_report(all_eff_labels, all_eff_preds, digits=4))\n",
    "                          \n",
    "accuracy = accuracy_score(all_m_labels, all_m_preds)\n",
    "print(\"----------------MobileNEt--------------------\\n\",f'Accuracy: {accuracy}')\n",
    "print(classification_report(all_m_labels, all_m_preds, digits=4))\n",
    "\n",
    "accuracy = accuracy_score(all_vgg_labels, all_vgg_preds)\n",
    "print(\"----------------VGG16--------------------\\n\",f'Accuracy: {accuracy}')\n",
    "print(classification_report(all_vgg_labels, all_vgg_preds, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66b8b2-332b-4362-b301-fd04dc05ea0e",
   "metadata": {},
   "source": [
    "## Hard Voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# Predict labels with models\n",
    "labels = []\n",
    "labels.append(all_resnet_preds)\n",
    "labels.append(all_resnet34_preds)\n",
    "labels.append(all_eff_preds)\n",
    "labels.append(all_vgg_preds)\n",
    "labels.append(all_m_preds)\n",
    "labels=np.asarray(labels)\n",
    "x=labels.T\n",
    "labels = np.squeeze(x)\n",
    "###Mode Pdrediction\n",
    "mode_info = stats.mode(labels, axis = 1)\n",
    "f = np.squeeze(mode_info[0]) \n",
    "\n",
    "accuracy=accuracy_score(true_labels, f)\n",
    "print(\"Hard Voting\\n Accuracy: \", accuracy)\n",
    "print(classification_report(true_labels, f, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aabd55-3c92-4186-ba08-4ee480d9e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# Predict labels with models\n",
    "labels = []\n",
    "labels.append(all_resnet_preds)\n",
    "labels.append(all_resnet34_preds)\n",
    "labels.append(all_eff_preds)\n",
    "#labels.append(all_m_preds)\n",
    "labels=np.asarray(labels)\n",
    "x=labels.T\n",
    "labels = np.squeeze(x)\n",
    "###Mode Pdrediction\n",
    "mode_info = stats.mode(labels, axis = 1)\n",
    "f = np.squeeze(mode_info[0]) \n",
    "\n",
    "accuracy=accuracy_score(true_labels, f)\n",
    "print(\"Hard Voting\\n Accuracy: \", accuracy)\n",
    "print(classification_report(true_labels, f, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy=accuracy_score(true_labels, f)\n",
    "print(\"Hard Voting\\n Accuracy: \", accuracy)\n",
    "print(classification_report(true_labels, f, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2848e7-8ef6-4f94-80f1-2919fdd91772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a PyTorch dataset object named 'dataset'\n",
    "class_names = dataset.classes\n",
    "class_names=['MD', 'MOD', 'ND', 'VMD']\n",
    "class_names\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, f)\n",
    "\n",
    "# Normalize confusion matrix\n",
    "conf_matrix_norm = normalize(conf_matrix, axis=1, norm='l1')\n",
    "\n",
    "# Define class labels\n",
    "classes = class_names\n",
    "\n",
    "# Plot normalized confusion matrix with a different colormap\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.set(font_scale=1.2)  # Adjust font scale for better readability\n",
    "sns.heatmap(conf_matrix_norm, annot=True, cmap='blues', fmt='.2f', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.savefig('CM96.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02114af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a PyTorch dataset object named 'dataset'\n",
    "class_names = dataset.classes\n",
    "class_names=['Mild', 'Moderate', 'Non', 'VeryMild']\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c689e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, f)\n",
    "\n",
    "# Normalize confusion matrix\n",
    "conf_matrix_norm = normalize(conf_matrix, axis=1, norm='l1')\n",
    "\n",
    "# Define class labels\n",
    "classes = class_names\n",
    "\n",
    "# Plot normalized confusion matrix with a different colormap\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.set(font_scale=1.2)  # Adjust font scale for better readability\n",
    "sns.heatmap(conf_matrix_norm, annot=True, cmap='blues', fmt='.2f', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199fd76f-22ca-4ef7-b6e9-f0330ae31058",
   "metadata": {},
   "source": [
    "## Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c962734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Collect predicted probabilities from models\n",
    "probabilities = []\n",
    "probabilities.append(all_resnet_probs)\n",
    "probabilities.append(all_resnet34_probs)\n",
    "probabilities.append(all_m_probs)\n",
    "probabilities.append(all_eff_probs)\n",
    "probabilities.append(all_vgg_probs)\n",
    "\n",
    "# Convert to numpy array\n",
    "probabilities = np.asarray(probabilities)\n",
    "\n",
    "# Transpose to have shape (samples, models, classes)\n",
    "probabilities = probabilities.transpose(1, 2, 0)\n",
    "\n",
    "# Calculate average probabilities across models\n",
    "average_probabilities = np.mean(probabilities, axis=2)\n",
    "\n",
    "# Get final predictions\n",
    "soft_voting_predictions = np.argmax(average_probabilities, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976448ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(true_labels, soft_voting_predictions)\n",
    "print(\"Soft Voting\\n Accuracy: \", accuracy)\n",
    "print(classification_report(true_labels, soft_voting_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d9fa6-ad7c-487c-9919-d8d49d58d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, soft_voting_predictions)\n",
    "\n",
    "# Normalize confusion matrix\n",
    "conf_matrix_norm = normalize(conf_matrix, axis=1, norm='l1')\n",
    "\n",
    "# Define class labels\n",
    "classes = class_names\n",
    "\n",
    "# Plot normalized confusion matrix with a different colormap\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.set(font_scale=1.2)  # Adjust font scale for better readability\n",
    "sns.heatmap(conf_matrix_norm, annot=True, cmap='YlGnBu', fmt='.2f', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47e472-cf00-4514-865d-1e5b7d6c4766",
   "metadata": {},
   "outputs": [],
   "source": [
    " import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "categories = ['MD', 'MOD', 'ND', 'VMD']\n",
    "precision_proto = [98.23, 99.4, 97.29, 95.01]\n",
    "recall_proto = [96.67, 99, 96.98, 96.67]\n",
    "f1_proto = [97.44, 99.2, 97.14, 95.83]\n",
    "\n",
    "# Dummy data for Proposed Model (SV) Classification Scores\n",
    "precision_proposed = [100, 100, 99.84, 99.37]\n",
    "recall_proposed = [100, 100, 99.84, 98.84]\n",
    "f1_proposed = [99.76, 100, 99.84, 99.60]\n",
    "\n",
    "# Creating a figure to hold the subplots\n",
    "plt.figure(figsize=(10, 3))  # Adjust the figure size as needed\n",
    "\n",
    "# Precision subplot\n",
    "plt.subplot(1, 3, 1)  # 1 row, 3 columns, 1st subplot\n",
    "plt.plot(categories, precision_proto, marker='o', label='ProtoNet4', linestyle='dashed', color='blue')\n",
    "plt.plot(categories, precision_proposed, marker='o', label='Proposed Model', color='blue')\n",
    "plt.ylabel('Score (%)')\n",
    "plt.ylim(90, 103)\n",
    "plt.title('Precision',fontsize=18)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Recall subplot\n",
    "plt.subplot(1, 3, 2)  # 1 row, 3 columns, 2nd subplot\n",
    "plt.plot(categories, recall_proto, marker='o', label='ProtoNet4 ', linestyle='dashed', color='red')\n",
    "plt.plot(categories, recall_proposed, marker='o', label='Proposed Model', color='red')\n",
    "plt.ylabel('Score (%)')\n",
    "plt.title('Recall',fontsize=18)\n",
    "plt.ylim(90, 103)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# F1-Score subplot\n",
    "plt.subplot(1, 3, 3)  # 1 row, 3 columns, 3rd subplot\n",
    "plt.plot(categories, f1_proto, marker='o', label='ProtoNet4 ', linestyle='dashed', color='green')\n",
    "plt.plot(categories, f1_proposed, marker='o', label='Proposed Model', color='green')\n",
    "plt.ylabel('Score (%)')\n",
    "plt.title('F1-Score',fontsize=18)\n",
    "plt.ylim(90, 103)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Modifying the spines for all plots\n",
    "for i in range(1, 4):\n",
    "    ax = plt.subplot(1, 3, i)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()  # Adjusts subplot params so that subplots are nicely fit in the figure area.\n",
    "plt.savefig('comp_metric_wise_horizontal.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768538cc-5511-4938-87ba-86cb43531b57",
   "metadata": {},
   "source": [
    "## Protonet (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9563ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with other network design\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PrototypicalNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(PrototypicalNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()  # Add a flattening layer to flatten the input tensor\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # Flatten the input tensor\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "    # coding=utf-8\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules import Module\n",
    "\n",
    "\n",
    "class PrototypicalLoss(Module):\n",
    "    '''\n",
    "    Loss class deriving from Module for the prototypical loss function defined below\n",
    "    '''\n",
    "    def __init__(self, n_support):\n",
    "        super(PrototypicalLoss, self).__init__()\n",
    "        self.n_support = n_support\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return prototypical_loss(input, target)#, self.n_support)\n",
    "\n",
    "\n",
    "def euclidean_dist(x, y):\n",
    "    '''\n",
    "    Compute euclidean distance between two tensors\n",
    "    '''\n",
    "    # x: N x D\n",
    "    # y: M x D\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "    if d != y.size(1):\n",
    "        raise Exception\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)\n",
    "\n",
    "\n",
    "def prototypical_loss(input, target):#, n_support):\n",
    "    '''\n",
    "    Inspired by https://github.com/jakesnell/prototypical-networks/blob/master/protonets/models/few_shot.py\n",
    "\n",
    "    Compute the barycentres by averaging the features of n_support\n",
    "    samples for each class in target, computes then the distances from each\n",
    "    samples' features to each one of the barycentres, computes the\n",
    "    log_probability for each n_query samples for each one of the current\n",
    "    classes, of appartaining to a class c, loss and accuracy are then computed\n",
    "    and returned\n",
    "    Args:\n",
    "    - input: the model output for a batch of samples\n",
    "    - target: ground truth for the above batch of samples\n",
    "    - n_support: number of samples to keep in account when computing\n",
    "      barycentres, for each one of the current classes\n",
    "    '''\n",
    "    target_cpu = target.to(device)\n",
    "    input_cpu = input.to(device)\n",
    "\n",
    "    def supp_idxs(c):\n",
    "        # FIXME when torch will support where as np\n",
    "        return target_cpu.eq(c).nonzero()[:n_support].squeeze(1)\n",
    "\n",
    "    # FIXME when torch.unique will be available on cuda too\n",
    "    classes = torch.unique(target_cpu)\n",
    "    n_classes = len(classes)\n",
    "    #print('n_classes:',n_classes)\n",
    "    # FIXME when torch will support where as np\n",
    "    # assuming n_query, n_target constants\n",
    "    n_query = target_cpu.eq(classes[0].item()).sum().item() - n_support\n",
    "    #print('n_query:',n_query)\n",
    "    support_idxs = list(map(supp_idxs, classes))\n",
    "\n",
    "    prototypes = torch.stack([input_cpu[idx_list].mean(0) for idx_list in support_idxs])\n",
    "    # FIXME when torch will support where as np\n",
    "    query_idxs = torch.stack(list(map(lambda c: target_cpu.eq(c).nonzero()[n_support:], classes))).view(-1)\n",
    "\n",
    "    query_samples = input.to(device)[query_idxs]\n",
    "    dists = euclidean_dist(query_samples, prototypes)\n",
    "\n",
    "    log_p_y = F.log_softmax(-dists, dim=1).view(n_classes, n_query, -1)\n",
    "\n",
    "    target_inds = torch.arange(0, n_classes, device=device)\n",
    "    target_inds = target_inds.view(n_classes, 1, 1)\n",
    "    target_inds = target_inds.expand(n_classes, n_query, 1).long()\n",
    "   # print('target_inds:',target_inds)\n",
    "\n",
    "    loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "    _, y_hat = log_p_y.max(2)\n",
    "    #print('y_hat',y_hat)\n",
    "    acc_val = y_hat.eq(target_inds.squeeze(2)).float().mean()\n",
    "    target_inds = target_inds.squeeze(2)\n",
    "    return loss_val,  acc_val, y_hat, target_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11313cc-6cfb-4e74-b4a6-a5df90f14945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the input_size to match the size of your extracted features\n",
    "input_size = 224*224*3  # Replace with the actual size of your features\n",
    "hidden_size = 128 #26  # 256 This can be adjusted as per your model's requirement\n",
    "\n",
    "proto_net = PrototypicalNetwork(input_size, hidden_size).to(device)\n",
    "# Prototypical Loss\n",
    "n_support = 10  # Adjust as needed\n",
    "proto_loss_fn = PrototypicalLoss(n_support).to(device)\n",
    "optimizer = torch.optim.Adam(proto_net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed7489-9196-47dd-912e-56d6ad7c4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses = []\n",
    "epoch_accuracies = [] \n",
    "\n",
    "# Training loop  hidden_size = 26 \n",
    "for epoch in range(100):\n",
    "    total_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = proto_net(features)\n",
    "        loss, acc, predictions, true_labels = proto_loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += acc.item()\n",
    "        total_batches += 1\n",
    "\n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = total_loss / total_batches\n",
    "    avg_accuracy = total_accuracy / total_batches\n",
    "    \n",
    "    # Store metrics\n",
    "    epoch_losses.append(avg_loss)\n",
    "    epoch_accuracies.append(avg_accuracy)\n",
    "    \n",
    "    # Log the training progress\n",
    "    print(f'Epoch {epoch}, Average Loss: {avg_loss:.4f}, Average Accuracy: {avg_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1fcdb3-2fb7-4955-96da-19a05c3b9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming you have a DataLoader named support_loader for the support set\n",
    "support_embeddings, support_labels = get_support_set_embeddings(test_loader, proto_net)\n",
    "# Convert to PyTorch tensors\n",
    "support_embeddings = torch.tensor(support_embeddings).to(device)\n",
    "support_labels = torch.tensor(support_labels).to(device)\n",
    "\n",
    "n_classes = 4\n",
    "# Compute the prototypes\n",
    "prototypes = compute_prototypes(support_embeddings, support_labels, n_classes)\n",
    "# In your evaluation loop\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        query_embeddings = proto_net(features)\n",
    "        predicted_labels = classify_embeddings(query_embeddings, prototypes)\n",
    "proto_net.eval()  # Assuming 'proto_net' is your Prototypical Network model\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:  # Replace eval_loader with your DataLoader for evaluation\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = proto_net(features)\n",
    "        preds, soft_assignments = classify_embeddings(embeddings,prototypes)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265a7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdaeb66-c776-447e-a4a0-0629f7e0862a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
